package compression.grammargenerator;

import compression.data.CachedDataset;
import compression.data.FolderBasedDataset;
import compression.GenericRNAEncoderForPrecision;
import compression.LocalConfig;
import compression.coding.ArithmeticEncoder;
import compression.coding.BitSizeOnlyArithmeticEncoder;
import compression.data.Dataset;
import compression.grammar.*;
import compression.parser.CYKParser;
import compression.parser.GrammarReaderNWriter;
import compression.parser.SRFParser;
import compression.samplegrammars.model.AdaptiveRuleProbModel;
import compression.samplegrammars.model.RuleProbModel;

import java.io.*;
import java.nio.channels.FileChannel;
import java.util.*;

public class ExhaustiveGrammarGenerator {

    static CharTerminal OP = new CharTerminal('(');
    static CharTerminal CL = new CharTerminal(')');
    static CharTerminal DT = new CharTerminal('.');


    public static void main (String[] args) throws IOException {

        //testingCYK();
        //testingSRF();
        //testingGrammarReaderNWriter();
        //testingAutoGeneratedGrammars(5);
        //copyFilesBestGrammars();

        //args[0] = name of folder containing RNAs to test for grammars which can parse RNA
        //args[1] = name of folder to store grammars which could parse RNAs
        //args[2] = name of folder to store grammars which could not parse RNAs
        //args[3] = Minimum number of rules for grammars
        //args[4] = Maximum number of rules for grammars
        //args[5] = Number of non-terminals

        if (args.length<7){
            System.out.println("ExhaustiveGrammarGenerator dataset outputForParsableGrammars " +
                    "outputForNonParsableGrammars minRules maxRules noNonterminals");
            System.out.println("Example: ExhaustiveGrammarGenerator Small_Dataset ParsableGrammars " +
                    "NonParsableGrammars 2 3 3");
            System.out.println("\tdataset: name of folder containing RNAs to test for grammars which can parse RNA");
            System.out.println("\toutputForParsableGrammars: name of folder to store grammars which could parse RNAs");
            System.out.println("\toutputForNonParsableGrammars: name of folder to store grammars which could not parse RNAs");
            System.out.println("\tminRules: Minimum number of rules for grammars");
            System.out.println("\tmaxRules: Maximum number of rules for grammars");
            System.out.println("\tnoNonterminals: Number of non-terminals");
            System.out.println("\tprintFailedGrammers: True or False");
            System.exit(98);
        }
        long startTime = System.nanoTime();


        //RsortByAverageCompressedBits("grammars_first_filter", "parsable");

        Dataset dataset = new FolderBasedDataset(args[0]);
        dataset = new CachedDataset(dataset, Comparator.comparing(rna -> rna.primaryStructure.length())); // make sure we don't access files in inner loop
        File outputForParsableGrammars = new File(LocalConfig.GIT_ROOT+"/grammars/"+args[1]);
        File outputForNonParsableGrammars = new File(LocalConfig.GIT_ROOT+"/grammars/"+args[2]);
        int minimumNoOfRules = Integer.parseInt(args[3]);
        int maximumNoOfRules = Integer.parseInt(args[4]);
        int noOfNonTerminals = Integer.parseInt(args[5]) - 1;
        boolean printFailedGrammars=Boolean.parseBoolean(args[6]);
        boolean printGoodGrammars=Boolean.parseBoolean(args[7]);
        if (!outputForParsableGrammars.exists()) outputForParsableGrammars.mkdirs();
        if (!outputForNonParsableGrammars.exists()) outputForNonParsableGrammars.mkdirs();

        getParsableGrammars(noOfNonTerminals, dataset, outputForParsableGrammars, outputForNonParsableGrammars, minimumNoOfRules, maximumNoOfRules, printFailedGrammars,printGoodGrammars);
        long endTime = System.nanoTime();

        long duration = (endTime - startTime);
        System.out.println(duration/1000000000/3600);


    }
    private static void testingSRF() {
        NonTerminal A0 = new NonTerminal("A0");
        NonTerminal A1 = new NonTerminal("A1");



        Grammar.Builder<PairOfCharTerminal> s= new Grammar.Builder<PairOfCharTerminal>("simpleGrammar",A0)
                .addRule(A0,DT)
                .addRule(A0, A0, A0)
                .addRule(A0, OP,A1,CL)
                .addRule(A1, OP,A1,CL)
                .addRule(A1, A0)
           ;


        Grammar simpleGrammar= s.build();
        SRFParser testingSRFParser = new SRFParser(simpleGrammar);


        List<Terminal<Character>> word = new ArrayList<>(Arrays.asList(DT,OP,DT,CL));

       // System.out.println(testingSRFParser.logProbabilityOf(word));
        //testingSRFParser.displayBooleanArray();
        //System.out.println(testingSRFParser.mostLikelyLeftmostDerivationFor(word));
       // System.out.println(testingSRFParser.mostLikelyWord(word));
        //testingCYKParser.displayCellContents();
    }

    private static void testingCYK() {
        NonTerminal S = new NonTerminal("S");
        NonTerminal O = new NonTerminal("O");
        NonTerminal A = new NonTerminal("A");
        NonTerminal D = new NonTerminal("D");
        NonTerminal B = new NonTerminal("B");
        NonTerminal C = new NonTerminal("C");
        NonTerminal E = new NonTerminal("E");
        NonTerminal F = new NonTerminal("F");


        Grammar.Builder<Character> s= new Grammar.Builder<Character>("simpleGrammar",S)
                .addRule(S, O, A)
                .addRule(S, O, D)
                .addRule(S, DT)
                .addRule(O, OP)
                .addRule(A, S, B)
                .addRule(B, C, S)
                .addRule(C, CL)
                .addRule(D, S, C)
                .addRule(S, F, S)
                .addRule(F, DT)
                ;


        Grammar<Character> simpleGrammar= s.build();
        CYKParser<Character> testingCYKParser = new CYKParser(simpleGrammar,null);


        List<Terminal<Character>> word = new ArrayList<>(Arrays.asList(DT,OP,DT,CL));
        System.out.println(testingCYKParser.mostLikelyLeftmostDerivationFor(word));
        System.out.println(testingCYKParser.mostLikelyWord(word));
        //testingCYKParser.displayCellContents();
    }

    private static void testingGrammarReaderNWriter() throws IOException {
        NonTerminal A0 = new NonTerminal("A0");
        NonTerminal A1 = new NonTerminal("A1");

        Grammar.Builder<Character> s = new Grammar.Builder<Character>("simpleGrammar1", A0)
                .addRule(A0,DT)
                .addRule(A0, A0, A0)
                .addRule(A0, OP,A1,CL)
                .addRule(A1, OP,A1,CL)
                .addRule(A1, A0)
                ;


        SecondaryStructureGrammar simpleGrammar1 = SecondaryStructureGrammar.fromCheap(s.build());


        GrammarReaderNWriter readerNWriter = new GrammarReaderNWriter("test");
        readerNWriter.writeGrammarToFile(simpleGrammar1);
        System.out.println(readerNWriter.getGrammarFromFile());
    }

    private static void getParsableGrammars(int no_of_nonTerminals, Dataset dataset, File grammars_that_parse, File grammars_that_fail, int minimum_no_of_rules, int maximum_no_of_rules, boolean printFailedGrammars, boolean printGoodGrammars) throws IOException {
        ParsableAutoGenGrammars PAGG = new ParsableAutoGenGrammars(no_of_nonTerminals, dataset, grammars_that_parse, grammars_that_fail, minimum_no_of_rules, maximum_no_of_rules, printFailedGrammars,printGoodGrammars );
        System.out.println(PAGG.getParsableGrammars());
        PAGG.printKTable();
    }

    public static void copyFilesBestGrammars()throws IOException{
        //File desination = new File("C:\\Users\\evita\\Documents\\GitHub\\compressed-rna\\grammars\\Best_grammars_Geomean_Adaptive_SemiAdaptive");
        File source = new File("C:\\Users\\evita\\Documents\\GitHub\\compressed-rna\\grammars\\grammars_first_filter");
        String[] files_to_select = {"grammar-2NTs-5rules-2574.txt","grammar-2NTs-5rules-2599.txt","grammar-2NTs-6rules-6526.txt",
                "grammar-2NTs-5rules-2602.txt","grammar-2NTs-5rules-2605.txt","grammar-2NTs-6rules-6825.txt",
                "grammar-2NTs-6rules-5291.txt","grammar-2NTs-6rules-6559.txt","grammar-2NTs-6rules-6562	.txt",
                "grammar-2NTs-6rules-6569.txt"};
        String[] list_from_sourcefile = source.list();

        for (int i=0; i<files_to_select.length;i++){
            for(int j=0; j<list_from_sourcefile.length; j++){
                if(files_to_select[i].equals(list_from_sourcefile[j])){
                    File sourceFile = new File("C:\\Users\\evita\\Documents\\GitHub\\compressed-rna\\grammars\\grammars_first_filter\\"+list_from_sourcefile[j]);
                    File dest = new File("C:\\Users\\evita\\Documents\\GitHub\\compressed-rna\\grammars\\Best_grammars_Geomean_Adaptive_SemiAdaptive\\"+files_to_select[i]);

                    //copy file conventional way using Stream
                    //long start = System.nanoTime();
                    copyFileUsingChannel(sourceFile, dest);
                }
            }
        }
    }
    public static void copyFiles() throws IOException {
        File desination = new File("C:/Users/evita/Documents/GitHub/compressed-rna/src/GrammarGenerator/Small_Dataset");
        File source = new File("C:/Users/evita/Documents/GitHub/compressed-rna/datasets/friemel-modified");
        String[] files_to_select = {"3892_120_c.txt", "3988_119_c.txt","12234_115_c.txt","4008_119_c.txt", "9732_121_c.txt", "925_122_c.txt",
                "10699_120_c.txt","13827_120_c.txt", "13748_119_c.txt","14892_119_c.txt","14250_118_c.txt", "14722_123_c.txt", "1182_122_c.txt",
                "863_119_c.txt","201_120_c.txt", "1795_118_c.txt", "1044_122_c.txt", "4906_119_c.txt", "8857_121_c.txt", "4350_120_c.txt", "3096_21_c.txt",
                "12157_23_c.txt", "363_22_c.txt", "2989_24_c.txt", "16694_20_c.txt", "16731_22_c.txt", "3730_16_c.txt", "12954_21_c.txt",
                "7052_16_c.txt", "16783_18_c.txt", "15564_21_c.txt", "7527_15_c.txt", "7205_14_c.txt", "2096_17_c.txt", "523_16_c.txt",
                "7883_16_c.txt", "12347_8_c.txt", "4266_8_c.txt", "437_8_c.txt", "456_2_c.txt", "2220_35_c.txt", "5006_30_c.txt",
                "3135_22_c.txt","12690_22_c.txt", "5340_45_c.txt", "2992_23_c.txt", "2462_25_c.txt", "16553_16_c.txt", "10090_41_c.txt",
                "6554_25_c.txt",  "9488_25_c.txt"," 266_35_c.txt", "3552_31_c.txt", "13007_45_c.txt", "5720_45_c.txt", "12084_32_c.txt", "16439_25_c.txt",
                "15060_40_c.txt", "983_60_c.txt", "456_2_c.txt", "8460_112_c.txt", "7917_117_c.txt", "15639_121_c.txt", "14542_119_c.txt", "165_120_c.txt",
                "4120_113_c.txt", "14931_120_c.txt", "13010_117_c.txt", "7217_122_c.txt", "13508_118_c.txt", "11608_118_c.txt", "15471_120_c.txt",
                "4646_120_c.txt",  "1850_117_c.txt","10457_115_c.txt",  "14329_120_c.txt",  "10023_120_c.txt", "7802_118_c.txt","2727_113_c.txt","1593_121_c.txt"};

        String[] list_from_sourcefile = source.list();

        for (int i=0; i<files_to_select.length;i++){
            for(int j=0; j<list_from_sourcefile.length; j++){
                if(files_to_select[i].equals(list_from_sourcefile[j])){
                    File sourceFile = new File("C:/Users/evita/Documents/GitHub/compressed-rna/datasets/friemel-modified/"+list_from_sourcefile[j]);
                    File dest = new File("C:/Users/evita/Documents/GitHub/compressed-rna/src/GrammarGenerator/Small_Dataset/"+files_to_select[i]);

                    //copy file conventional way using Stream
                    //long start = System.nanoTime();
                    copyFileUsingChannel(sourceFile, dest);
                }
            }
        }
    }

    private static void copyFileUsingChannel(File source, File dest) throws IOException {
        FileChannel sourceChannel = null;
        FileChannel destChannel = null;
        try {
            sourceChannel = new FileInputStream(source).getChannel();
            destChannel = new FileOutputStream(dest).getChannel();
            destChannel.transferFrom(sourceChannel, 0, sourceChannel.size());
        }finally{
            sourceChannel.close();
            destChannel.close();
        }
    }

    private static void sortByAverageCompressedBits(String folderNameForGrammars, String folderNameForRnas) throws IOException {

        List<RNAGrammar> listOfGrammars = new ArrayList<>();
        File grammarFiles = new File(LocalConfig.GIT_ROOT+"/src/GrammarGenerator/"+folderNameForGrammars);
        File[] listOfFiles = grammarFiles.listFiles();

        System.out.println(listOfFiles.length);
        for(File file: listOfFiles) {
            System.out.println(file.getName());
            //
            listOfGrammars.add(RNAGrammar.from(new GrammarReaderNWriter(file.getPath()).getGrammarFromFile(),false));
        }
        Dataset dataset= new FolderBasedDataset(folderNameForRnas);
        Map<String, Double> GrammarToAverageCompression= new HashMap<>();

        double averageCompression=0.0;
        double total_compression_ratio=0.0;
        double compression_ratio=0.0;
        int encodedLength;

        for(RNAGrammar g: listOfGrammars) {

            for (RNAWithStructure RNAWS : dataset) {
                ///////////*************compression using adaptive model
                ArithmeticEncoder AE2 = new BitSizeOnlyArithmeticEncoder();
                RuleProbModel RPMAdaptive = new AdaptiveRuleProbModel(g);
                // GenericRNAEncoder GRAdaptive = new GenericRNAEncoder(RPMAdaptive, AE2, G.getGrammar(), G.getStartSymbol());
                GenericRNAEncoderForPrecision GRAdaptive = new GenericRNAEncoderForPrecision(RPMAdaptive, AE2, g, g.startSymbol);
                //String encodedStringAdaptive = GRAdaptive.encodeRNA(RNAWS);
                 encodedLength = GRAdaptive.getPrecisionForRNACode(RNAWS);
                compression_ratio=(double)encodedLength/(double)RNAWS.getNumberOfBases();
                System.out.println(compression_ratio+" "+g.name);
                //System.exit(0);
                total_compression_ratio+=compression_ratio;
            }

            averageCompression=(double)total_compression_ratio/ (double)dataset.getSize();
            GrammarToAverageCompression.put(g.name, averageCompression);
            //System.out.println(g.name+" "+ averageCompression);
            //System.exit(0);
            //averageCompression=0.0;
            total_compression_ratio=0.0;

        }

        try (BufferedWriter bf = new BufferedWriter(new FileWriter(LocalConfig.GIT_ROOT+"/src/GrammarGenerator/Grammar_to_compression_ratio.txt")))
        {
            bf.write("Grammar Name\t\t"+ "Average Compression Ratio" );
            bf.newLine();
            for(String str: GrammarToAverageCompression.keySet()) {
                bf.write(str + "\t\t" + GrammarToAverageCompression.get(str));
                bf.newLine();
            }

        } catch (IOException e) {
            throw new RuntimeException(e);
        }

    }

}
